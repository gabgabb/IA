{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.828181800Z",
     "start_time": "2023-05-24T13:12:59.824181900Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# 1.1 Importer les données Train et Test\n",
    "\n",
    "train_clean = pd.read_csv(\"/home/gabgab/dev/IA/deepLearning/data/Module3/train_clean.csv\")\n",
    "\n",
    "test_clean = pd.read_csv(\"/home/gabgab/dev/IA/deepLearning/data/Module3/test_clean.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.831181200Z",
     "start_time": "2023-05-24T13:12:59.830244300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# 1.2 Depuis le Dataframe train, charger les features d'apprentissage dans un array numpy X_alltrain, et les labels (données à prévoir) dans un array numpy y_alltrain\n",
    "\n",
    "X_alltrain = train_clean.values[:, 2:]\n",
    "y_alltrain = train_clean.values[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.831756600Z",
     "start_time": "2023-05-24T13:12:59.830244300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X_train : (801, 7)\n",
      "Dimensions de y_train : (801,)\n",
      "Dimensions de X_dev : (90, 7)\n",
      "Dimensions de y_dev : (90,)\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Séparer les features et les labels en deux parties (train et dev), en attribuant 10% des exemples aux données de dev. Afficher les nombres de lignes et de colonnes pour les 4 arrays.\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_alltrain, y_alltrain, test_size=0.1, random_state=42)\n",
    "\n",
    "print(\"Dimensions de X_train :\", X_train.shape)\n",
    "print(\"Dimensions de y_train :\", y_train.shape)\n",
    "print(\"Dimensions de X_dev :\", X_dev.shape)\n",
    "print(\"Dimensions de y_dev :\", y_dev.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.832761300Z",
     "start_time": "2023-05-24T13:12:59.831181200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 premières lignes de X_train :\n",
      " [[3 1 0 2 0 0 4]\n",
      " [3 0 0 3 0 0 2]\n",
      " [1 1 3 3 0 1 1]\n",
      " [3 1 2 0 2 1 1]\n",
      " [3 1 0 0 0 1 1]\n",
      " [3 1 1 0 0 1 1]\n",
      " [1 1 2 3 0 0 1]\n",
      " [3 1 2 1 0 1 1]\n",
      " [2 0 2 1 0 1 3]\n",
      " [3 1 1 0 0 1 1]]\n",
      "10 premiers éléments de y_train :\n",
      " [1 0 0 0 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# 1.4 Afficher les 10 premières lignes de features et les 10 premiers labels.\n",
    "\n",
    "print(\"10 premières lignes de X_train :\\n\", X_train[:10, :])\n",
    "\n",
    "print(\"10 premiers éléments de y_train :\\n\", y_train[:10])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.833761400Z",
     "start_time": "2023-05-24T13:12:59.831756600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# 2.1 Définir et instancier une classe Titanic Model avec les caractéristiques suivantes :\n",
    "#  - Deux couches cachées de 50 neurones.\n",
    "#  - Deux classes en sortie : Survivant ou non\n",
    "#  - Des fonctions d'activation RELU\n",
    "#  - Un dropout paramétrable pour les 2 couches cachées\n",
    "\n",
    "class TitanicModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout_rate):\n",
    "        super(TitanicModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]  # Assuming X_train is a numpy array\n",
    "hidden_size = 50\n",
    "output_size = 2  # Assuming binary classification (survived or not)\n",
    "dropout_rate = 0.5\n",
    "\n",
    "titanic = TitanicModel(input_size, hidden_size, output_size, dropout_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.833761400Z",
     "start_time": "2023-05-24T13:12:59.831756600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# 2.2 Définir des paramètres de nombre d'epochs (50) et de learning_rate (0.01)\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.836765200Z",
     "start_time": "2023-05-24T13:12:59.832761300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# 2.3 Définir la taille du minibatch à 50. En déduire le nombre de boucles pour chaque epoch.\n",
    "\n",
    "batch_size = 50\n",
    "num_batches = len(X_train) // batch_size\n",
    "num_steps_per_epoch = num_batches + 1 if len(X_train) % batch_size != 0 else num_batches"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.841765200Z",
     "start_time": "2023-05-24T13:12:59.835765300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# 2.4 Définir une fonction de coût de type CrossEntropy\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.989092800Z",
     "start_time": "2023-05-24T13:12:59.841765200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# 2.5. Définir un optimizer de type Adam, sans oublier le learning rate\n",
    "\n",
    "optimizer = optim.Adam(titanic.parameters(), learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:12:59.989092800Z",
     "start_time": "2023-05-24T13:12:59.883444300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.5194\n",
      "Epoch 10: Loss = 0.4576\n",
      "Epoch 15: Loss = 0.4323\n",
      "Epoch 20: Loss = 0.4459\n",
      "Epoch 25: Loss = 0.4518\n",
      "Epoch 30: Loss = 0.4369\n",
      "Epoch 35: Loss = 0.4476\n",
      "Epoch 40: Loss = 0.4432\n",
      "Epoch 45: Loss = 0.4334\n",
      "Epoch 50: Loss = 0.4252\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Exécuter l'apprentissage du modèle.\n",
    "#  - Créer une boucle sur les epochs, qui contient elle-même une boucle sur les minibatchs.\n",
    "#  - À chaque nouvelle itération sur les epochs, mélanger les données avec la méthode shuffle.\n",
    "#  - Tous les 5 epochs afficher la valeur de la fonction de cout\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "num_iterations = len(X_train) // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "    total_loss = 0\n",
    "    for iteration in range(num_iterations):\n",
    "        start = iteration * batch_size\n",
    "        end = (iteration + 1) * batch_size\n",
    "        inputs = torch.Tensor(X_train[start:end])\n",
    "        labels = torch.LongTensor(y_train[start:end])\n",
    "        optimizer.zero_grad()\n",
    "        outputs = titanic(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss / num_iterations:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:13:00.327807900Z",
     "start_time": "2023-05-24T13:12:59.884448600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on dev set: 81.11%\n"
     ]
    }
   ],
   "source": [
    "# 3.2 Calculer la précision de la prévision sur les données dev\n",
    "\n",
    "titanic.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    dev_inputs = torch.Tensor(X_dev)\n",
    "    dev_labels = torch.Tensor(y_dev)\n",
    "    dev_outputs = titanic(dev_inputs)\n",
    "    _, predicted = torch.max(dev_outputs.data, 1)\n",
    "    total = dev_labels.size(0)\n",
    "    correct = (predicted == dev_labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "\n",
    "print('Accuracy on dev set: {:.2f}%'.format(accuracy * 100))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:13:00.365732Z",
     "start_time": "2023-05-24T13:13:00.320240200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 1, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# 3.3 Calculer prévisions sur les données de tests\n",
    "\n",
    "titanic.eval()\n",
    "X_test = test_clean.iloc[:, 1:].values\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs_test = torch.Tensor(X_test)\n",
    "    outputs_test = titanic(inputs_test)\n",
    "    _, predicted_test = torch.max(outputs_test, 1)\n",
    "\n",
    "print(predicted_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:26:15.668257Z",
     "start_time": "2023-05-24T13:26:15.658976200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# 3.4 Générer le fichier résultat et l'envoyer sur kaggle. Quel est votre score et votre classement ?\n",
    "\n",
    "result_df = pd.DataFrame({'PassengerId': test_clean['PassengerId'], 'Survived': predicted_test})\n",
    "result_df.to_csv('result.csv', index=False)\n",
    "\n",
    "# Score: 0.77990 / Classement 3428\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:26:21.287347800Z",
     "start_time": "2023-05-24T13:26:21.284349200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate: 0.001, Keep Prob: 0.5, Epochs: 50, Accuracy: 0.7510\n",
      "Learning Rate: 0.001, Keep Prob: 0.5, Epochs: 100, Accuracy: 0.7880\n",
      "Learning Rate: 0.001, Keep Prob: 0.5, Epochs: 150, Accuracy: 0.8002\n",
      "Learning Rate: 0.001, Keep Prob: 0.7, Epochs: 50, Accuracy: 0.7588\n",
      "Learning Rate: 0.001, Keep Prob: 0.7, Epochs: 100, Accuracy: 0.7891\n",
      "Learning Rate: 0.001, Keep Prob: 0.7, Epochs: 150, Accuracy: 0.7924\n",
      "Learning Rate: 0.001, Keep Prob: 0.9, Epochs: 50, Accuracy: 0.7576\n",
      "Learning Rate: 0.001, Keep Prob: 0.9, Epochs: 100, Accuracy: 0.7913\n",
      "Learning Rate: 0.001, Keep Prob: 0.9, Epochs: 150, Accuracy: 0.8048\n",
      "Learning Rate: 0.01, Keep Prob: 0.5, Epochs: 50, Accuracy: 0.7969\n",
      "Learning Rate: 0.01, Keep Prob: 0.5, Epochs: 100, Accuracy: 0.8059\n",
      "Learning Rate: 0.01, Keep Prob: 0.5, Epochs: 150, Accuracy: 0.8170\n",
      "Learning Rate: 0.01, Keep Prob: 0.7, Epochs: 50, Accuracy: 0.8092\n",
      "Learning Rate: 0.01, Keep Prob: 0.7, Epochs: 100, Accuracy: 0.8025\n",
      "Learning Rate: 0.01, Keep Prob: 0.7, Epochs: 150, Accuracy: 0.8070\n",
      "Learning Rate: 0.01, Keep Prob: 0.9, Epochs: 50, Accuracy: 0.8081\n",
      "Learning Rate: 0.01, Keep Prob: 0.9, Epochs: 100, Accuracy: 0.8036\n",
      "Learning Rate: 0.01, Keep Prob: 0.9, Epochs: 150, Accuracy: 0.8081\n",
      "Learning Rate: 0.1, Keep Prob: 0.5, Epochs: 50, Accuracy: 0.7373\n",
      "Learning Rate: 0.1, Keep Prob: 0.5, Epochs: 100, Accuracy: 0.7126\n",
      "Learning Rate: 0.1, Keep Prob: 0.5, Epochs: 150, Accuracy: 0.7485\n",
      "Learning Rate: 0.1, Keep Prob: 0.7, Epochs: 50, Accuracy: 0.7193\n",
      "Learning Rate: 0.1, Keep Prob: 0.7, Epochs: 100, Accuracy: 0.7407\n",
      "Learning Rate: 0.1, Keep Prob: 0.7, Epochs: 150, Accuracy: 0.7520\n",
      "Learning Rate: 0.1, Keep Prob: 0.9, Epochs: 50, Accuracy: 0.7025\n",
      "Learning Rate: 0.1, Keep Prob: 0.9, Epochs: 100, Accuracy: 0.7609\n",
      "Learning Rate: 0.1, Keep Prob: 0.9, Epochs: 150, Accuracy: 0.7103\n",
      "Best Parameters:\n",
      "{'learning_rate': 0.01, 'keep_prob': 0.5, 'epochs': 150}\n",
      "Best Accuracy:\n",
      "0.817048521750047\n"
     ]
    }
   ],
   "source": [
    "# 3.5 Exécuter une cross-validation dans une boucle pour trouver les meilleures valeurs de learning rate, de keep_prob et de nombre d'epochs.\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "keep_probs = [0.5, 0.7, 0.9]\n",
    "num_epochs = [50, 100, 150]\n",
    "num_folds = 5\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "kf = KFold(n_splits=num_folds)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for kp in keep_probs:\n",
    "        for epochs in num_epochs:\n",
    "            accuracies = []\n",
    "\n",
    "            for train_index, dev_index in kf.split(X_alltrain):\n",
    "                X_train, X_dev = X_alltrain[train_index], X_alltrain[dev_index]\n",
    "                y_train, y_dev = y_alltrain[train_index], y_alltrain[dev_index]\n",
    "\n",
    "                model = TitanicModel(input_size, hidden_size, output_size, dropout_rate)\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                for epoch in range(epochs):\n",
    "                    model.train()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    outputs = model(torch.Tensor(X_train))\n",
    "                    loss = criterion(outputs, torch.LongTensor(y_train).type(torch.long))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(torch.Tensor(X_dev))\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    y_dev_tensor = torch.from_numpy(y_dev)\n",
    "                    accuracy = torch.eq(predicted, torch.Tensor(y_dev)).sum().item() / len(y_dev)\n",
    "                    accuracies.append(accuracy)\n",
    "\n",
    "            avg_accuracy = sum(accuracies) / len(accuracies)\n",
    "            print(f\"Learning Rate: {lr}, Keep Prob: {kp}, Epochs: {epochs}, Accuracy: {avg_accuracy:.4f}\")\n",
    "\n",
    "            if avg_accuracy > best_accuracy:\n",
    "                best_accuracy = avg_accuracy\n",
    "                best_params['learning_rate'] = lr\n",
    "                best_params['keep_prob'] = kp\n",
    "                best_params['epochs'] = epochs\n",
    "\n",
    "print(\"Best Parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best Accuracy:\")\n",
    "print(best_accuracy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-24T13:42:54.484807200Z",
     "start_time": "2023-05-24T13:42:43.627797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
